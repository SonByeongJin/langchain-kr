{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 랭스미스 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-teddynote in c:\\users\\sbj57\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-7dbpt-ne-py3.11\\lib\\site-packages (0.3.44)\n",
      "Requirement already satisfied: langchain in c:\\users\\sbj57\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-7dbpt-ne-py3.11\\lib\\site-packages (from langchain-teddynote) (0.3.21)\n",
      "Requirement already satisfied: langgraph in c:\\users\\sbj57\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-7dbpt-ne-py3.11\\lib\\site-packages (from langchain-teddynote) (0.3.16)\n",
      "Requirement already satisfied: kiwipiepy in c:\\users\\sbj57\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-7dbpt-ne-py3.11\\lib\\site-packages (from langchain-teddynote) (0.20.4)\n",
      "Requirement already satisfied: rank_bm25 in c:\\users\\sbj57\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-7dbpt-ne-py3.11\\lib\\site-packages (from langchain-teddynote) (0.2.2)\n",
      "Requirement already satisfied: pinecone-client[grpc] in c:\\users\\sbj57\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-7dbpt-ne-py3.11\\lib\\site-packages (from langchain-teddynote) (3.2.2)\n",
      "Requirement already satisfied: pinecone-text in c:\\users\\sbj57\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-7dbpt-ne-py3.11\\lib\\site-packages (from langchain-teddynote) (0.10.0)\n",
      "Requirement already satisfied: olefile in c:\\users\\sbj57\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-7dbpt-ne-py3.11\\lib\\site-packages (from langchain-teddynote) (0.47)\n",
      "Requirement already satisfied: pdf2image in c:\\users\\sbj57\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-7dbpt-ne-py3.11\\lib\\site-packages (from langchain-teddynote) (1.17.0)\n",
      "Requirement already satisfied: openai in c:\\users\\sbj57\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-7dbpt-ne-py3.11\\lib\\site-packages (from langchain-teddynote) (1.66.5)\n",
      "Requirement already satisfied: anthropic in c:\\users\\sbj57\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-7dbpt-ne-py3.11\\lib\\site-packages (from langchain-teddynote) (0.49.0)\n",
      "Requirement already satisfied: deepl in c:\\users\\sbj57\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-7dbpt-ne-py3.11\\lib\\site-packages (from langchain-teddynote) (1.21.1)\n",
      "Requirement already satisfied: feedparser in c:\\users\\sbj57\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-7dbpt-ne-py3.11\\lib\\site-packages (from langchain-teddynote) (6.0.11)\n",
      "Requirement already satisfied: tavily-python in c:\\users\\sbj57\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-7dbpt-ne-py3.11\\lib\\site-packages (from langchain-teddynote) (0.5.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\sbj57\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-7dbpt-ne-py3.11\\lib\\site-packages (from langchain-teddynote) (2.2.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\sbj57\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-7dbpt-ne-py3.11\\lib\\site-packages (from anthropic->langchain-teddynote) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\sbj57\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-7dbpt-ne-py3.11\\lib\\site-packages (from anthropic->langchain-teddynote) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\sbj57\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-7dbpt-ne-py3.11\\lib\\site-packages (from anthropic->langchain-teddynote) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\sbj57\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-7dbpt-ne-py3.11\\lib\\site-packages (from anthropic->langchain-teddynote) (0.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\sbj57\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-7dbpt-ne-py3.11\\lib\\site-packages (from anthropic->langchain-teddynote) (2.10.6)\n",
      "Requirement already satisfied: sniffio in c:\\users\\sbj57\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-7dbpt-ne-py3.11\\lib\\site-packages (from anthropic->langchain-teddynote) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in c:\\users\\sbj57\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-7dbpt-ne-py3.11\\lib\\site-packages (from anthropic->langchain-teddynote) (4.12.2)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\sbj57\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-7dbpt-ne-py3.11\\lib\\site-packages (from deepl->langchain-teddynote) (2.32.3)\n",
      "Requirement already satisfied: sgmllib3k in c:\\users\\sbj57\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-7dbpt-ne-py3.11\\lib\\site-packages (from feedparser->langchain-teddynote) (1.0.0)\n",
      "Requirement already satisfied: kiwipiepy_model<0.21,>=0.20 in c:\\users\\sbj57\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-7dbpt-ne-py3.11\\lib\\site-packages (from kiwipiepy->langchain-teddynote) (0.20.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\sbj57\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-7dbpt-ne-py3.11\\lib\\site-packages (from kiwipiepy->langchain-teddynote) (1.26.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\sbj57\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-7dbpt-ne-py3.11\\lib\\site-packages (from kiwipiepy->langchain-teddynote) (4.67.1)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.45 in c:\\users\\sbj57\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-7dbpt-ne-py3.11\\lib\\site-packages (from langchain->langchain-teddynote) (0.3.45)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.7 in c:\\users\\sbj57\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-7dbpt-ne-py3.11\\lib\\site-packages (from langchain->langchain-teddynote) (0.3.7)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in c:\\users\\sbj57\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-7dbpt-ne-py3.11\\lib\\site-packages (from langchain->langchain-teddynote) (0.3.16)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\sbj57\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-7dbpt-ne-py3.11\\lib\\site-packages (from langchain->langchain-teddynote) (2.0.39)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\sbj57\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-7dbpt-ne-py3.11\\lib\\site-packages (from langchain->langchain-teddynote) (6.0.2)\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.10 in c:\\users\\sbj57\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-7dbpt-ne-py3.11\\lib\\site-packages (from langgraph->langchain-teddynote) (2.0.21)\n",
      "Requirement already satisfied: langgraph-prebuilt<0.2,>=0.1.1 in c:\\users\\sbj57\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-7dbpt-ne-py3.11\\lib\\site-packages (from langgraph->langchain-teddynote) (0.1.3)\n",
      "Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.42 in c:\\users\\sbj57\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-7dbpt-ne-py3.11\\lib\\site-packages (from langgraph->langchain-teddynote) (0.1.57)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\sbj57\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-7dbpt-ne-py3.11\\lib\\site-packages (from pandas->langchain-teddynote) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sbj57\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-7dbpt-ne-py3.11\\lib\\site-packages (from pandas->langchain-teddynote) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\sbj57\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-7dbpt-ne-py3.11\\lib\\site-packages (from pandas->langchain-teddynote) (2025.1)\n",
      "Requirement already satisfied: pillow in c:\\users\\sbj57\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-7dbpt-ne-py3.11\\lib\\site-packages (from pdf2image->langchain-teddynote) (10.4.0)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in c:\\users\\sbj57\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-7dbpt-ne-py3.11\\lib\\site-packages (from pinecone-client[grpc]->langchain-teddynote) (2025.1.31)\n",
      "Requirement already satisfied: googleapis-common-protos>=1.53.0 in c:\\users\\sbj57\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-7dbpt-ne-py3.11\\lib\\site-packages (from pinecone-client[grpc]->langchain-teddynote) (1.69.2)\n",
      "Requirement already satisfied: grpc-gateway-protoc-gen-openapiv2==0.1.0 in c:\\users\\sbj57\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-7dbpt-ne-py3.11\\lib\\site-packages (from pinecone-client[grpc]->langchain-teddynote) (0.1.0)\n",
      "Requirement already satisfied: grpcio>=1.59.0 in c:\\users\\sbj57\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-7dbpt-ne-py3.11\\lib\\site-packages (from pinecone-client[grpc]->langchain-teddynote) (1.67.1)\n",
      "Requirement already satisfied: lz4>=3.1.3 in c:\\users\\sbj57\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-7dbpt-ne-py3.11\\lib\\site-packages (from pinecone-client[grpc]->langchain-teddynote) (4.4.3)\n",
      "Requirement already satisfied: protobuf<3.21.0,>=3.20.0 in c:\\users\\sbj57\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-7dbpt-ne-py3.11\\lib\\site-packages (from pinecone-client[grpc]->langchain-teddynote) (3.20.3)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in c:\\users\\sbj57\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-7dbpt-ne-py3.11\\lib\\site-packages (from pinecone-client[grpc]->langchain-teddynote) (2.3.0)\n",
      "Requirement already satisfied: mmh3<5.0.0,>=4.1.0 in c:\\users\\sbj57\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-7dbpt-ne-py3.11\\lib\\site-packages (from pinecone-text->langchain-teddynote) (4.1.0)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.9.1 in c:\\users\\sbj57\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-7dbpt-ne-py3.11\\lib\\site-packages (from pinecone-text->langchain-teddynote) (3.9.1)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in c:\\users\\sbj57\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-7dbpt-ne-py3.11\\lib\\site-packages (from pinecone-text->langchain-teddynote) (1.0.1)\n",
      "Requirement already satisfied: types-requests<3.0.0,>=2.25.0 in c:\\users\\sbj57\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-7dbpt-ne-py3.11\\lib\\site-packages (from pinecone-text->langchain-teddynote) (2.32.0.20250306)\n",
      "Requirement already satisfied: tiktoken>=0.5.1 in c:\\users\\sbj57\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-7dbpt-ne-py3.11\\lib\\site-packages (from tavily-python->langchain-teddynote) (0.9.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\sbj57\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-7dbpt-ne-py3.11\\lib\\site-packages (from anyio<5,>=3.5.0->anthropic->langchain-teddynote) (3.10)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\sbj57\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-7dbpt-ne-py3.11\\lib\\site-packages (from httpx<1,>=0.23.0->anthropic->langchain-teddynote) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\sbj57\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-7dbpt-ne-py3.11\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->anthropic->langchain-teddynote) (0.14.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\sbj57\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-7dbpt-ne-py3.11\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.45->langchain->langchain-teddynote) (8.5.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\sbj57\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-7dbpt-ne-py3.11\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.45->langchain->langchain-teddynote) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\sbj57\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-7dbpt-ne-py3.11\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.45->langchain->langchain-teddynote) (24.2)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in c:\\users\\sbj57\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-7dbpt-ne-py3.11\\lib\\site-packages (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph->langchain-teddynote) (1.1.0)\n",
      "Requirement already satisfied: orjson>=3.10.1 in c:\\users\\sbj57\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-7dbpt-ne-py3.11\\lib\\site-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph->langchain-teddynote) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\sbj57\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-7dbpt-ne-py3.11\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain->langchain-teddynote) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\sbj57\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-7dbpt-ne-py3.11\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain->langchain-teddynote) (0.23.0)\n",
      "Requirement already satisfied: click in c:\\users\\sbj57\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-7dbpt-ne-py3.11\\lib\\site-packages (from nltk<4.0.0,>=3.9.1->pinecone-text->langchain-teddynote) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\sbj57\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-7dbpt-ne-py3.11\\lib\\site-packages (from nltk<4.0.0,>=3.9.1->pinecone-text->langchain-teddynote) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\sbj57\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-7dbpt-ne-py3.11\\lib\\site-packages (from nltk<4.0.0,>=3.9.1->pinecone-text->langchain-teddynote) (2024.11.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\sbj57\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-7dbpt-ne-py3.11\\lib\\site-packages (from pydantic<3,>=1.9.0->anthropic->langchain-teddynote) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\sbj57\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-7dbpt-ne-py3.11\\lib\\site-packages (from pydantic<3,>=1.9.0->anthropic->langchain-teddynote) (2.27.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sbj57\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-7dbpt-ne-py3.11\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->langchain-teddynote) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sbj57\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-7dbpt-ne-py3.11\\lib\\site-packages (from requests<3,>=2->deepl->langchain-teddynote) (3.4.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\sbj57\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-7dbpt-ne-py3.11\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain->langchain-teddynote) (3.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\sbj57\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-7dbpt-ne-py3.11\\lib\\site-packages (from tqdm->kiwipiepy->langchain-teddynote) (0.4.6)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\sbj57\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-7dbpt-ne-py3.11\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.45->langchain->langchain-teddynote) (3.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-teddynote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "Test_01\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(\"Test_01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 하지 않습니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote import logging\n",
    "\n",
    "# set_enable=False 로 지정하면 추적을 하지 않습니다.\n",
    "logging.langsmith(\"랭체인 튜토리얼 프로젝트\", set_enable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI API 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "CH01-Basic\n"
     ]
    }
   ],
   "source": [
    "# LangSmith 추적을 설정합니다. https://smith.langchain.com\n",
    "# .env 파일에 LANGCHAIN_API_KEY를 입력합니다.\n",
    "# !pip install -qU langchain-teddynote\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(\"CH01-Basic\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[답변]: content='대한민국의 수도는 서울입니다.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 16, 'total_tokens': 25, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_86d0290411', 'id': 'chatcmpl-BHhlcyfpAoF6TPTTylXMQTwlHxfL5', 'finish_reason': 'stop', 'logprobs': None} id='run-185f9900-047b-4fb0-952f-989e715cfd08-0' usage_metadata={'input_tokens': 16, 'output_tokens': 9, 'total_tokens': 25, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 객체 생성\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.1,  # 창의성 (0.0 ~ 2.0)\n",
    "    model_name=\"gpt-4o-mini\",  # 모델명\n",
    ")\n",
    "\n",
    "# 질의내용\n",
    "question = \"대한민국의 수도는 어디인가요?\"\n",
    "\n",
    "# 질의\n",
    "print(f\"[답변]: {llm.invoke(question)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질의내용\n",
    "question = \"대한민국의 수도는 어디인가요?\"\n",
    "\n",
    "# 질의\n",
    "response = llm.invoke(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='대한민국의 수도는 서울입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 16, 'total_tokens': 25, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_86d0290411', 'id': 'chatcmpl-BHhlmeB67fuCIALgcPUaHJc07ggGl', 'finish_reason': 'stop', 'logprobs': None}, id='run-eceee29c-d644-4dd5-a2c4-1d63699b3257-0', usage_metadata={'input_tokens': 16, 'output_tokens': 9, 'total_tokens': 25, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'대한민국의 수도는 서울입니다.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_usage': {'completion_tokens': 9,\n",
       "  'prompt_tokens': 16,\n",
       "  'total_tokens': 25,\n",
       "  'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
       "   'audio_tokens': 0,\n",
       "   'reasoning_tokens': 0,\n",
       "   'rejected_prediction_tokens': 0},\n",
       "  'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}},\n",
       " 'model_name': 'gpt-4o-mini-2024-07-18',\n",
       " 'system_fingerprint': 'fp_86d0290411',\n",
       " 'id': 'chatcmpl-BHhlmeB67fuCIALgcPUaHJc07ggGl',\n",
       " 'finish_reason': 'stop',\n",
       " 'logprobs': None}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.response_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogProb 활성화\n",
    "\n",
    "주어진 텍스트에 대한 모델의 **토큰 확률의 로그 값** 을 의미합니다. 토큰이란 문장을 구성하는 개별 단어나 문자 등의 요소를 의미하고, 확률은 **모델이 그 토큰을 예측할 확률**을 나타냅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 객체 생성\n",
    "llm_with_logprob = ChatOpenAI(\n",
    "    temperature=0.1,  # 창의성 (0.0 ~ 2.0)\n",
    "    max_tokens=2048,  # 최대 토큰수\n",
    "    model_name=\"gpt-4o-mini\",  # 모델명\n",
    ").bind(logprobs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질의내용\n",
    "question = \"대한민국의 수도는 어디인가요?\"\n",
    "\n",
    "# 질의\n",
    "response = llm_with_logprob.invoke(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='대한민국의 수도는 서울입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 16, 'total_tokens': 25, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_86d0290411', 'id': 'chatcmpl-BHhnxn38o3pcTX2VAlYe8hNNwhrf8', 'finish_reason': 'stop', 'logprobs': {'content': [{'token': '대한', 'bytes': [235, 140, 128, 237, 149, 156], 'logprob': -3.881560041918419e-05, 'top_logprobs': []}, {'token': '민국', 'bytes': [235, 175, 188, 234, 181, 173], 'logprob': -6.704273118884885e-07, 'top_logprobs': []}, {'token': '의', 'bytes': [236, 157, 152], 'logprob': -2.7968066206085496e-05, 'top_logprobs': []}, {'token': ' 수도', 'bytes': [32, 236, 136, 152, 235, 143, 132], 'logprob': -5.633853652398102e-05, 'top_logprobs': []}, {'token': '는', 'bytes': [235, 138, 148], 'logprob': -5.538490950129926e-05, 'top_logprobs': []}, {'token': ' 서울', 'bytes': [32, 236, 132, 156, 236, 154, 184], 'logprob': -0.00019591135787777603, 'top_logprobs': []}, {'token': '입니다', 'bytes': [236, 158, 133, 235, 139, 136, 235, 139, 164], 'logprob': -0.0016298363916575909, 'top_logprobs': []}, {'token': '.', 'bytes': [46], 'logprob': -1.9361264946837764e-07, 'top_logprobs': []}], 'refusal': None}}, id='run-bb866cc3-b0ec-4ede-a728-12fe32e2c57c-0', usage_metadata={'input_tokens': 16, 'output_tokens': 9, 'total_tokens': 25, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_usage': {'completion_tokens': 9,\n",
       "  'prompt_tokens': 16,\n",
       "  'total_tokens': 25,\n",
       "  'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
       "   'audio_tokens': 0,\n",
       "   'reasoning_tokens': 0,\n",
       "   'rejected_prediction_tokens': 0},\n",
       "  'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}},\n",
       " 'model_name': 'gpt-4o-mini-2024-07-18',\n",
       " 'system_fingerprint': 'fp_86d0290411',\n",
       " 'id': 'chatcmpl-BHhnxn38o3pcTX2VAlYe8hNNwhrf8',\n",
       " 'finish_reason': 'stop',\n",
       " 'logprobs': {'content': [{'token': '대한',\n",
       "    'bytes': [235, 140, 128, 237, 149, 156],\n",
       "    'logprob': -3.881560041918419e-05,\n",
       "    'top_logprobs': []},\n",
       "   {'token': '민국',\n",
       "    'bytes': [235, 175, 188, 234, 181, 173],\n",
       "    'logprob': -6.704273118884885e-07,\n",
       "    'top_logprobs': []},\n",
       "   {'token': '의',\n",
       "    'bytes': [236, 157, 152],\n",
       "    'logprob': -2.7968066206085496e-05,\n",
       "    'top_logprobs': []},\n",
       "   {'token': ' 수도',\n",
       "    'bytes': [32, 236, 136, 152, 235, 143, 132],\n",
       "    'logprob': -5.633853652398102e-05,\n",
       "    'top_logprobs': []},\n",
       "   {'token': '는',\n",
       "    'bytes': [235, 138, 148],\n",
       "    'logprob': -5.538490950129926e-05,\n",
       "    'top_logprobs': []},\n",
       "   {'token': ' 서울',\n",
       "    'bytes': [32, 236, 132, 156, 236, 154, 184],\n",
       "    'logprob': -0.00019591135787777603,\n",
       "    'top_logprobs': []},\n",
       "   {'token': '입니다',\n",
       "    'bytes': [236, 158, 133, 235, 139, 136, 235, 139, 164],\n",
       "    'logprob': -0.0016298363916575909,\n",
       "    'top_logprobs': []},\n",
       "   {'token': '.',\n",
       "    'bytes': [46],\n",
       "    'logprob': -1.9361264946837764e-07,\n",
       "    'top_logprobs': []}],\n",
       "  'refusal': None}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.response_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 스트리밍 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = llm.stream(\"대한민국의 아름다운 관광지 10곳 주소 알려줘\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "대한민국에는 아름다운 관광지가 많이 있습니다. 아래는 추천하는 10곳과 그 주소입니다.\n",
      "\n",
      "1. **경복궁**\n",
      "   - 주소: 서울특별시 종로구 사직로 161\n",
      "\n",
      "2. **제주도**\n",
      "   - 주소: 제주특별자치도 제주시\n",
      "\n",
      "3. **부산 해운대**\n",
      "   - 주소: 부산광역시 해운대구 해운대해변로 140\n",
      "\n",
      "4. **경주 불국사**\n",
      "   - 주소: 경상북도 경주시 불국로 385\n",
      "\n",
      "5. **남이섬**\n",
      "   - 주소: 강원도 춘천시 남이섬길 1\n",
      "\n",
      "6. **전주 한옥마을**\n",
      "   - 주소: 전라북도 전주시 완산구 기린대로 99\n",
      "\n",
      "7. **설악산 국립공원**\n",
      "   - 주소: 강원도 속초시 설악산로 173\n",
      "\n",
      "8. **안동 하회마을**\n",
      "   - 주소: 경상북도 안동시 풍천면 하회리\n",
      "\n",
      "9. **서울 남산타워 (N서울타워)**\n",
      "   - 주소: 서울특별시 용산구 남산공원길 105\n",
      "\n",
      "10. **광주 무등산**\n",
      "    - 주소: 광주광역시 동구 무등산로 1\n",
      "\n",
      "각 관광지는 고유의 매력을 가지고 있으니, 방문 계획 시 참고하시기 바랍니다!"
     ]
    }
   ],
   "source": [
    "for token in answer:\n",
    "    print(token.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "대한민국에는 아름다운 관광지가 많이 있습니다. 아래는 추천하는 10곳과 그 주소입니다.\n",
      "\n",
      "1. **경복궁**\n",
      "   - 주소: 서울특별시 종로구 사직로 161\n",
      "\n",
      "2. **제주도**\n",
      "   - 주소: 제주특별자치도 제주시\n",
      "\n",
      "3. **부산 해운대 해수욕장**\n",
      "   - 주소: 부산광역시 해운대구 해운대해변로 264\n",
      "\n",
      "4. **경주 불국사**\n",
      "   - 주소: 경상북도 경주시 불국로 385\n",
      "\n",
      "5. **남이섬**\n",
      "   - 주소: 강원도 춘천시 남이섬길 1\n",
      "\n",
      "6. **전주 한옥마을**\n",
      "   - 주소: 전라북도 전주시 완산구 기린대로 99\n",
      "\n",
      "7. **설악산 국립공원**\n",
      "   - 주소: 강원도 속초시 설악산로 173\n",
      "\n",
      "8. **안동 하회마을**\n",
      "   - 주소: 경상북도 안동시 풍천면 하회리\n",
      "\n",
      "9. **서울 남산타워 (N서울타워)**\n",
      "   - 주소: 서울특별시 용산구 남산공원길 105\n",
      "\n",
      "10. **광주 무등산**\n",
      "    - 주소: 광주광역시 동구 무등산로 100\n",
      "\n",
      "각 관광지는 고유의 매력을 가지고 있으며, 방문 시 다양한 문화와 자연을 경험할 수 있습니다."
     ]
    }
   ],
   "source": [
    "from langchain_teddynote.messages import stream_response\n",
    "\n",
    "# 스트림 방식으로 질의\n",
    "# answer 에 스트리밍 답변의 결과를 받습니다.\n",
    "answer = llm.stream(\"대한민국의 아름다운 관광지 10곳과 주소를 알려주세요!\")\n",
    "stream_response(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 프롬프트 캐싱"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 프롬프트 캐싱 기능을 활용하면 반복하여 동일한 입력으로 들어가는 토큰 비용 줄일 수 있음.\n",
    "- 다만, 캐싱에 활용할 토큰은 **고정된 PREFIX** 를 주는 것이 권장됨\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.messages import stream_response\n",
    "\n",
    "very_long_prompt = \"\"\"\n",
    "당신은 매우 친절한 AI 어시스턴트 입니다. \n",
    "당신의 임무는 주어진 질문에 대해 친절하게 답변하는 것입니다.\n",
    "아래는 사용자의 질문에 답변할 때 참고할 수 있는 정보입니다.\n",
    "주어진 정보를 참고하여 답변해 주세요.\n",
    "\n",
    "<WANT_TO_CACHE_HERE>\n",
    "#참고:\n",
    "**Prompt Caching**\n",
    "Model prompts often contain repetitive content, like system prompts and common instructions. OpenAI routes API requests to servers that recently processed the same prompt, making it cheaper and faster than processing a prompt from scratch. This can reduce latency by up to 80% and cost by 50% for long prompts. Prompt Caching works automatically on all your API requests (no code changes required) and has no additional fees associated with it.\n",
    "\n",
    "Prompt Caching is enabled for the following models:\n",
    "\n",
    "gpt-4o (excludes gpt-4o-2024-05-13 and chatgpt-4o-latest)\n",
    "gpt-4o-mini\n",
    "o1-preview\n",
    "o1-mini\n",
    "This guide describes how prompt caching works in detail, so that you can optimize your prompts for lower latency and cost.\n",
    "\n",
    "Structuring prompts\n",
    "Cache hits are only possible for exact prefix matches within a prompt. To realize caching benefits, place static content like instructions and examples at the beginning of your prompt, and put variable content, such as user-specific information, at the end. This also applies to images and tools, which must be identical between requests.\n",
    "\n",
    "How it works\n",
    "Caching is enabled automatically for prompts that are 1024 tokens or longer. When you make an API request, the following steps occur:\n",
    "\n",
    "Cache Lookup: The system checks if the initial portion (prefix) of your prompt is stored in the cache.\n",
    "Cache Hit: If a matching prefix is found, the system uses the cached result. This significantly decreases latency and reduces costs.\n",
    "Cache Miss: If no matching prefix is found, the system processes your full prompt. After processing, the prefix of your prompt is cached for future requests.\n",
    "Cached prefixes generally remain active for 5 to 10 minutes of inactivity. However, during off-peak periods, caches may persist for up to one hour.\n",
    "\n",
    "Requirements\n",
    "Caching is available for prompts containing 1024 tokens or more, with cache hits occurring in increments of 128 tokens. Therefore, the number of cached tokens in a request will always fall within the following sequence: 1024, 1152, 1280, 1408, and so on, depending on the prompt's length.\n",
    "\n",
    "All requests, including those with fewer than 1024 tokens, will display a cached_tokens field of the usage.prompt_tokens_details chat completions object indicating how many of the prompt tokens were a cache hit. For requests under 1024 tokens, cached_tokens will be zero.\n",
    "\n",
    "What can be cached\n",
    "Messages: The complete messages array, encompassing system, user, and assistant interactions.\n",
    "Images: Images included in user messages, either as links or as base64-encoded data, as well as multiple images can be sent. Ensure the detail parameter is set identically, as it impacts image tokenization.\n",
    "Tool use: Both the messages array and the list of available tools can be cached, contributing to the minimum 1024 token requirement.\n",
    "Structured outputs: The structured output schema serves as a prefix to the system message and can be cached.\n",
    "Best practices\n",
    "Structure prompts with static or repeated content at the beginning and dynamic content at the end.\n",
    "Monitor metrics such as cache hit rates, latency, and the percentage of tokens cached to optimize your prompt and caching strategy.\n",
    "To increase cache hits, use longer prompts and make API requests during off-peak hours, as cache evictions are more frequent during peak times.\n",
    "Prompts that haven't been used recently are automatically removed from the cache. To minimize evictions, maintain a consistent stream of requests with the same prompt prefix.\n",
    "Frequently asked questions\n",
    "How is data privacy maintained for caches?\n",
    "\n",
    "Prompt caches are not shared between organizations. Only members of the same organization can access caches of identical prompts.\n",
    "\n",
    "Does Prompt Caching affect output token generation or the final response of the API?\n",
    "\n",
    "Prompt Caching does not influence the generation of output tokens or the final response provided by the API. Regardless of whether caching is used, the output generated will be identical. This is because only the prompt itself is cached, while the actual response is computed anew each time based on the cached prompt. \n",
    "\n",
    "Is there a way to manually clear the cache?\n",
    "\n",
    "Manual cache clearing is not currently available. Prompts that have not been encountered recently are automatically cleared from the cache. Typical cache evictions occur after 5-10 minutes of inactivity, though sometimes lasting up to a maximum of one hour during off-peak periods.\n",
    "\n",
    "Will I be expected to pay extra for writing to Prompt Caching?\n",
    "\n",
    "No. Caching happens automatically, with no explicit action needed or extra cost paid to use the caching feature.\n",
    "\n",
    "Do cached prompts contribute to TPM rate limits?\n",
    "\n",
    "Yes, as caching does not affect rate limits.\n",
    "\n",
    "Is discounting for Prompt Caching available on Scale Tier and the Batch API?\n",
    "\n",
    "Discounting for Prompt Caching is not available on the Batch API but is available on Scale Tier. With Scale Tier, any tokens that are spilled over to the shared API will also be eligible for caching.\n",
    "\n",
    "Does Prompt Caching work on Zero Data Retention requests?\n",
    "\n",
    "Yes, Prompt Caching is compliant with existing Zero Data Retention policies.\n",
    "</WANT_TO_CACHE_HERE>\n",
    "\n",
    "#Question:\n",
    "{}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens Used: 1206\n",
      "\tPrompt Tokens: 1138\n",
      "\t\tPrompt Tokens Cached: 0\n",
      "\tCompletion Tokens: 68\n",
      "\t\tReasoning Tokens: 0\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.0002115\n",
      "캐싱된 토큰: 0\n"
     ]
    }
   ],
   "source": [
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "with get_openai_callback() as cb:\n",
    "    answer = llm.invoke(\n",
    "        very_long_prompt.format(\"프롬프트 캐싱 기능에 대해 2문장으로 설명하세요\")\n",
    "    )\n",
    "    print(cb)\n",
    "    cached_tokens = answer.response_metadata[\"token_usage\"][\"prompt_tokens_details\"][\"cached_tokens\"]\n",
    "    print(f\"캐싱된 토큰: {cached_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens Used: 1200\n",
      "\tPrompt Tokens: 1138\n",
      "\t\tPrompt Tokens Cached: 1024\n",
      "\tCompletion Tokens: 62\n",
      "\t\tReasoning Tokens: 0\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.0001311\n",
      "캐싱된 토큰: 1024\n"
     ]
    }
   ],
   "source": [
    "with get_openai_callback() as cb:\n",
    "    # 답변 요청\n",
    "    answer = llm.invoke(\n",
    "        very_long_prompt.format(\"프롬프트 캐싱 기능에 대해 2문장으로 설명하세요\")\n",
    "    )\n",
    "    print(cb)\n",
    "    # 캐싱된 토큰 출력\n",
    "    cached_tokens = answer.response_metadata[\"token_usage\"][\"prompt_tokens_details\"][\"cached_tokens\"]\n",
    "    print(f\"캐싱된 토큰: {cached_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 멀티모달은 생략(토큰이슈)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-7DBPT-nE-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
